{"cells": [{"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n! pip install geocoder\nimport geocoder", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Collecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): done\nSolving environment: - ", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "df = pd.read_csv('https://raw.githubusercontent.com/haanjiankur/Capstone-Project---The-Battle-of-Neighborhoods/master/zomato.csv',encoding='ISO-8859-1')\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_india = df[df['Country Code'] == 1]\ndf_NDLS = df_india[df_india['City'] == 'New Delhi']\ndf_NDLS.reset_index(drop=True, inplace=True)\ndf_NDLS.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ndf_Res= df_NDLS[df_NDLS.Longitude !=0.000000][['Restaurant Name','Locality','Longitude','Latitude','Cuisines','Aggregate rating','Rating text','Votes']]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_Res = df_Res[df_Res['Aggregate rating'] !=0.0]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_Res.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nNew_Delhi_Rest = folium.Map(location=[28.52, 77.25], zoom_start=12)\n\nX = df_Res['Latitude']\nY = df_Res['Longitude']\nZ = np.stack((X, Y), axis=1)\n\nkmeans = KMeans(n_clusters=5, random_state=0).fit(Z)\n\nclusters = kmeans.labels_\ncolors = ['red', 'green', 'blue', 'yellow','orange']\ndf_Res ['Cluster'] = clusters\n\nfor latitude, longitude, Locality, cluster in zip(df_Res['Latitude'], df_Res['Longitude'], df_Res['Locality'], df_Res['Cluster']):\n    label = folium.Popup(Locality, parse_html=True)\n    folium.CircleMarker(\n        [latitude, longitude],\n        radius=5,\n        popup=label,\n        color='black',\n        fill=True,\n        fill_color=colors[cluster],\n        fill_opacity=0.7).add_to(New_Delhi_Rest)  \n\nNew_Delhi_Rest", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_Res.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(9,5), dpi = 100)\n# title\nplt.title('The highest rated resturant in top 10 locality of New Delhi')\n#On x-axis\n\n#giving a bar plot\ndf_Res.groupby('Locality')['Aggregate rating'].mean().nlargest(10).plot(kind='bar')\n\nplt.xlabel('Resturant Locality in New Delhi')\n#On y-axis\nplt.ylabel('Aggregate Rating')\n#displays the plot\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nplt.figure(figsize=(9,5), dpi = 100)\n# title\nplt.title('The Worst rated resturant in top 10 locality of New Delhi')\n#On x-axis\n\n#giving a bar plot\n\ndf_Res.groupby('Locality')['Aggregate rating'].mean().nsmallest(10).plot(kind='bar')\n\nplt.xlabel('Resturant Locality in New Delhi')\n#On y-axis\nplt.ylabel('Aggregate Rating')\n\n#displays the plot\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nplt.figure(figsize=(9,5), dpi = 100)\n# title\nplt.title('The highest number of Restaurant available in Locality of New Delhi')\n#On x-axis\n\n#giving a bar plot\ndf_Res.groupby('Locality')['Restaurant Name'].count().nlargest(10).plot(kind='bar')\n\nplt.xlabel('Resturant Locality in New Delhi')\n#On y-axis\nplt.ylabel('Number of Restaurant')\n\n#displays the plot\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(9,5), dpi = 100)\n# title\nplt.title('The lowest number of Restaurant available in Locality of New Delhi')\n#On x-axis\n\n#giving a bar plot\ndf_Res.groupby('Locality')['Restaurant Name'].count().nsmallest(10).plot(kind='bar')\n\nplt.xlabel('Resturant Locality in New Delhi')\n#On y-axis\nplt.ylabel('Number of Restaurant')\n\n#displays the plot\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nplt.figure(figsize=(9,5), dpi = 100)\n# title\nplt.title('The best Locality for chinese restaurant in New Delhi city')\n#On x-axis\n\n#giving a bar plot\ndf_Res[df_Res['Cuisines'].str.startswith('Chinese')].groupby('Locality')['Restaurant Name'].count().nlargest(5).plot(kind='bar')\n\nplt.xlabel('Resturant Locality in New Delhi')\n#On y-axis\nplt.ylabel('Number of Chinese Restaurant')\n\n#displays the plot\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nplt.figure(figsize=(9,5), dpi = 100)\n# title\nplt.title('The best places for Chinese restaurant in New Delhi city')\n#On x-axis\n\n#giving a bar plot\ndf_Res[df_Res['Cuisines'].str.startswith('Chinese')].groupby('Locality')['Aggregate rating'].mean().nlargest(5).plot(kind='bar')\n\nplt.xlabel('Resturant Locality in New Delhi')\n#On y-axis\nplt.ylabel('Rating of resturants')\n\n#displays the plot\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ndf_Res_Loc =  df_Res.groupby('Locality').count()['Restaurant Name'].to_frame()\ndf_Res_rating= df_Res.groupby('Locality')['Aggregate rating'].mean().to_frame()\nd_Cuisines = df_Res.groupby(['Locality'])['Cuisines'].agg(', '.join).reset_index()\nd_R = df_Res.groupby(['Locality'])['Rating text'].unique().agg(', '.join).reset_index()\nd_V = df_Res.groupby(['Locality'])['Votes'].sum().to_frame()\nd_Lat = df_Res.groupby('Locality').mean()['Latitude'].to_frame()\nd_Lng = df_Res.groupby('Locality').mean()['Longitude'].to_frame()\ndf_final = pd.merge(d_Lat,d_Lng,on='Locality').merge(df_Res_Loc, on='Locality').merge(d_Cuisines, on='Locality').merge(df_Res_rating,on ='Locality').merge(d_R, on ='Locality').merge(d_V, on ='Locality')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_final = df_final[df_final['Aggregate rating'] != 0.000000]\ndf_final.columns =['Locality','Lat','Lng', 'No_of_Restaurant','Cusines', 'Agg_Rating','Comments' ,'No_of_Votes']\ndf_final.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n## Define Foursquare Credentials and Version\nCLIENT_ID = 'ES3ZXR1ALGY0Q0YQVMG0RUMAO00WTUNG4K1C2JN5C2J0O1AZ' # Foursquare ID\nCLIENT_SECRET = 'H3VNVPRCUTEX4NP23B4ANBLXWZKKIZ0VM4NKN0IQRYPYXPTW' # Foursquare Secret\nVERSION = '20180605' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## create a function to repeat the same process to all the Locality in New Delhi\n\ndef getNearbyVenues(names, latitudes, longitudes, radius=500,LIMIT = 100):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n        \n nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Locality', \n                  'Locality Latitude', \n                  'Locality Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# find the venues in all New Delhi Locality\nnew_Delhi_venues = getNearbyVenues(names=df_final['Locality'],\n                                   latitudes=df_final['Lat'],\n                                   longitudes=df_final['Lng']\n                                  )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "new_Delhi_venues.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('There are {} uniques categories.'.format(len(new_Delhi_venues['Venue Category'].unique())))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n## Analyze Each Locality\n\n# one hot encoding\nnew_Delhi_onehot = pd.get_dummies(new_Delhi_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add Locality column back to dataframe\nnew_Delhi_onehot['Locality'] = new_Delhi_venues['Locality'] \n\n# move Locality column to the first column\ncolumn_list = new_Delhi_onehot.columns.tolist()\ncolumn_number = int(column_list.index('Locality'))\ncolumn_list = [column_list[column_number]] + column_list[:column_number] + column_list[column_number+1:]\nnew_Delhi_onehot = new_Delhi_onehot[column_list]\n\nnew_Delhi_onehot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "New_Delhi_grouped.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n## print each Locality along with the top 5 most common venues\n\nnum_top_venues = 5\n\nfor hood in New_Delhi_grouped['Locality']:\n    print(\"----\"+hood+\"----\")\n    temp = New_Delhi_grouped[New_Delhi_grouped['Locality'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n## put that into a pandas dataframe\n## First, write a function to sort the venues in descending order.\n\ndef return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n## create the new dataframe and display the top 10 venues for each Locality.\n\nnum_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Locality']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nLocality_venues_sorted = pd.DataFrame(columns=columns)\nLocality_venues_sorted['Locality'] = New_Delhi_grouped['Locality']\n\nfor ind in np.arange(New_Delhi_grouped.shape[0]):\n    Locality_venues_sorted.iloc[ind, 1:] = return_most_common_venues(New_Delhi_grouped.iloc[ind, :], num_top_venues)\n\nLocality_venues_sorted", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## Cluster Locality\n## Run k-means to cluster the Locality into 5 clusters.\n\n# set number of clusters\nkclusters = 5\n\nNew_Delhi_clustering = New_Delhi_grouped.drop('Locality', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(New_Delhi_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] \nkmeans.labels_.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# add clustering labels\nNew_Delhi_merged = df_final.head(240)\nNew_Delhi_merged['Cluster Labels'] = kmeans.labels_\n\n# merge New_Delhi_grouped with df_Chinese to add latitude/longitude for each Locality\nNew_Delhi_merged = New_Delhi_merged.join(Locality_venues_sorted.set_index('Locality'), on='Locality')\n\nNew_Delhi_merged.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# create final map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\n#colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n#rainbow = [colors.rgb2hex(i) for i in colors_array]\ncolors = ['red', 'green', 'blue', 'yellow','orange']\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(New_Delhi_merged['Lat'], New_Delhi_merged['Lng'], New_Delhi_merged['Locality'], New_Delhi_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color='black',\n        fill=True,\n        fill_color=colors[cluster],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## Examine Clusters\n\n## Cluster 1\nNew_Delhi_merged.loc[New_Delhi_merged['Cluster Labels'] == 0, New_Delhi_merged.columns[[1] + list(range(5, New_Delhi_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## Examine Clusters\n\n## Cluster 2\nNew_Delhi_merged.loc[New_Delhi_merged['Cluster Labels'] == 1, New_Delhi_merged.columns[[1] + list(range(5, New_Delhi_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## Examine Clusters\n\n## Cluster 3\nNew_Delhi_merged.loc[New_Delhi_merged['Cluster Labels'] == 2, New_Delhi_merged.columns[[1] + list(range(5, New_Delhi_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## Examine Clusters\n\n## Cluster 4\nNew_Delhi_merged.loc[New_Delhi_merged['Cluster Labels'] ==3 , New_Delhi_merged.columns[[1] + list(range(5, New_Delhi_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}